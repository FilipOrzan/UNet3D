Last version of code before improve the model
from google.colab import drive
drive.mount('/content/drive')

#other cell
# -*- coding: utf-8 -*-
"""
Created on Mon Nov 25 19:25:39 2024

@author: user
"""

import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import nibabel as nib
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import torch.nn.functional as F

# Define 3D U-Net model
class UNet3D(nn.Module):
    def __init__(self):
        super(UNet3D, self).__init__()

        def CBR(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),
                nn.BatchNorm3d(out_channels),
                nn.ReLU(inplace=True),
                nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),
                nn.BatchNorm3d(out_channels),
                nn.ReLU(inplace=True)
            )

        # Encoder
        self.enc1 = CBR(1, 64)
        self.enc2 = CBR(64, 128)
        self.enc3 = CBR(128, 256)
        self.enc4 = CBR(256, 512)

        # Decoder
        self.dec1 = CBR(512 + 256, 256)
        self.dec2 = CBR(256 + 128, 128)
        self.dec3 = CBR(128 + 64, 64)
        self.final = nn.Conv3d(64, 1, kernel_size=1)

        # Pooling and Upsampling
        self.pool = nn.MaxPool3d(2)
        #self.up = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)
        self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)

    def forward(self, x):
        # Encoder
        enc1 = self.enc1(x)
        enc2 = self.enc2(self.pool(enc1))
        enc3 = self.enc3(self.pool(enc2))
        enc4 = self.enc4(self.pool(enc3))

        # Decoder
        # Realizează upsampling
        up_enc4 = self.up(enc4)

        # Ajustează dimensiunile dacă nu sunt identice
        if up_enc4.size(2) != enc3.size(2) or up_enc4.size(3) != enc3.size(3) or up_enc4.size(4) != enc3.size(4):
            diffZ = enc3.size(2) - up_enc4.size(2)
            diffY = enc3.size(3) - up_enc4.size(3)
            diffX = enc3.size(4) - up_enc4.size(4)

            up_enc4 = torch.nn.functional.pad(up_enc4,
                                      (diffX // 2, diffX - diffX // 2,
                                       diffY // 2, diffY - diffY // 2,
                                       diffZ // 2, diffZ - diffZ // 2))

        # Concatenează
        dec1 = self.dec1(torch.cat([up_enc4, enc3], dim=1))
        dec2 = self.dec2(torch.cat([self.up(dec1), enc2], dim=1))
        # Realizează upsampling
        up_dec2 = self.up(dec2)

        # Ajustează dimensiunile dacă nu sunt identice
        if up_dec2.size(2) != enc1.size(2) or up_dec2.size(3) != enc1.size(3) or up_dec2.size(4) != enc1.size(4):
            diffZ = enc1.size(2) - up_dec2.size(2)
            diffY = enc1.size(3) - up_dec2.size(3)
            diffX = enc1.size(4) - up_dec2.size(4)

            up_dec2 = torch.nn.functional.pad(up_dec2,
                                      (diffX // 2, diffX - diffX // 2,
                                       diffY // 2, diffY - diffY // 2,
                                       diffZ // 2, diffZ - diffZ // 2))

# Concatenează
        dec3 = self.dec3(torch.cat([up_dec2, enc1], dim=1))
        final = self.final(dec3)

        return torch.sigmoid(final)
# Only execute training if the script is run directly
if __name__ == "__main__":
    model = UNet3D()
    # Training logic here
    torch.save(model.state_dict(), "trained_3d_unet.pth")
# Dataset class for 3D NIfTI files



class Nii3DDataset(Dataset):
    def __init__(self, image_dir, mask_dir, crop_size=None, transform=None):
        """
        Args:
            image_dir (str): Directory with input image files.
            mask_dir (str): Directory with mask files.
            crop_size (tuple, optional): Desired crop size (depth, height, width). Default is None (no cropping).
            transform (callable, optional): Optional transform to apply to samples.
        """
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.crop_size = crop_size
        self.images = [f for f in os.scandir(image_dir) if f.is_file() and f.name.endswith('.gz')]

    def __len__(self):
        return len(self.images)

    def crop_center(self, image, crop_size):
        """
        Crop the center of a 3D volume.
        Args:
            image (numpy array): Input 3D volume.
            crop_size (tuple): Desired crop size (depth, height, width).
        Returns:
            numpy array: Cropped 3D volume.
        """
        depth, height, width = image.shape
        crop_depth, crop_height, crop_width = crop_size

        start_d = (depth - crop_depth) // 2
        start_h = (height - crop_height) // 2
        start_w = (width - crop_width) // 2

        return image[start_d:start_d + crop_depth, start_h:start_h + crop_height, start_w:start_w + crop_width]

    def __getitem__(self, idx):
        image_path = os.path.join(self.image_dir, self.images[idx])
        mask_path = os.path.join(self.mask_dir, self.images[idx])

        # Load NIfTI files
        image = nib.load(image_path).get_fdata()
        mask = nib.load(mask_path).get_fdata()

        # Normalize image and ensure mask is binary
        image = (image - np.min(image)) / (np.max(image) - np.min(image))
        mask = (mask > 0).astype(np.float32)

        # Apply cropping if crop_size is specified
        if self.crop_size is not None:
            image = self.crop_center(image, self.crop_size)
            mask = self.crop_center(mask, self.crop_size)

        # Convert to tensors and add channel dimension
        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Shape: (1, D, H, W)
        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)    # Shape: (1, D, H, W)

        return image, mask



# Define paths
image_dir = '/content/drive/MyDrive/Algoritmi_An_III/gztraining/image/' # Replace with the path to your image NIfTI files
mask_dir = '/content/drive/MyDrive/Algoritmi_An_III/gztraining/mask/'    # Replace with your 3D NIfTI mask directory
print("Fișiere în image_dir:", os.listdir(image_dir))
print("Fișiere în mask_dir:", os.listdir(mask_dir))
# Hyperparameters
batch_size = 1
learning_rate = 0.1
num_epochs = 1
# Desired crop size
crop_size = (128, 128, 128)  # Depth, Height, Width

# Initialize dataset with cropping
dataset = Nii3DDataset(image_dir, mask_dir, crop_size=crop_size)

# Prepare DataLoader
dataloader = DataLoader(dataset, batch_size=1, shuffle=True)


# Initialize model, loss function, and optimizer
model = UNet3D()
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training function
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

print("Linia 146")
for epoch in range(num_epochs):
    model.train()
    print("Linia 149")
    epoch_loss = 0
    for images, masks in dataloader:
        images, masks = images.to(device), masks.to(device)
        print("Linia 153")
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, masks)
        print("Linia 157")
        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print("Linia 162")
        epoch_loss += loss.item()
        pass
    pass
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader):.4f}")

print("Training complete.")
torch.save(model.state_dict(), 'trained_3d_unet.pth')
print("Model saved as 'trained_3d_unet.pth'")
